{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tasks\n",
    "### 1: Form training and testing periods as discussed (2 test periods, last 2*365 days). Be careful tp scale data only based on data from the training set. You may use (from Python) MinMaxScaler, standardisation (StandardScaler) or the default scaler in Python's elastic net.\n",
    "### 2:Estimate the current flu rates by training an elastic net model. Use a Pearson correlation filter (r > 0.3) on the training data to reduce the amount of queries prior to training an elastic net (reminder: not all 1000 queries I provided are related to flu!). Report performance on the two test sets using three metrics: mean absolute error, root mean squared error and Pearson's correlation.\n",
    "### 3: If there is time, begin work on traditional forecasting models (you've identified seasonal ARIMA and Hult-Winters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import csv\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import math\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from random import randint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.nonparametric.kde import KDEUnivariate\n",
    "from statsmodels.nonparametric import smoothers_lowess\n",
    "from pandas import Series, DataFrame\n",
    "from patsy import dmatrices\n",
    "from sklearn import datasets, svm\n",
    "\n",
    "# initialize the plotting sizes\n",
    "# set size\n",
    "plt.rc('figure', figsize=(15, 8))\n",
    "# subplots size\n",
    "fizsize_with_subplots = (15, 8)\n",
    "# histogram size\n",
    "bin_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "dates = pd.read_csv('data/dates.csv',header=None)\n",
    "queries = pd.read_csv('data/queries.csv',header=None)\n",
    "X = pd.read_csv('data/X.csv',header=None)\n",
    "y = pd.read_csv('data/y.csv',header=None)\n",
    "\n",
    "X.columns = queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (4383, 500)   y shape:  (4383, 1)\n",
      "train1 X: (3618, 500)  train1 y: (3618, 1)  Test1 X shape: (365, 500)  Test1 y shape: (365, 1)\n",
      "validation1 X: (400, 500)  validation1 y: (400, 1)\n",
      "train2 X: (3293, 500)  train2 y: (3293, 1)  Test2 X: (365, 500)  Test2 y: (365, 1)\n",
      "validation2 X: (360, 500)  validation2 y: (360, 1)\n"
     ]
    }
   ],
   "source": [
    "# data preprocessing and train-test split\n",
    "# this data is well formed with no missing value and other symbols or labels that are non numerical.\n",
    "# splitting the data into train and test\n",
    "\n",
    "# Here we want the first 500 queries\n",
    "X = X.iloc[:, 0: 500]\n",
    "\n",
    "# first with the last year as test\n",
    "# for convinience, pick the two validation set starting from 1/3 and 2/3 of the training set,\n",
    "# 10% of training set as validation, here use 400 data points, two 200 periods.\n",
    "test_size =365\n",
    "length = X.shape[0]\n",
    "l =(X.shape[0]-test_size)//3\n",
    "\n",
    "train1_X = pd.concat([X[0:l],X[l+200:2*l],X[2*l+200:length-test_size]])\n",
    "val1_X = pd.concat([X[l:l+200],X[2*l:2*l+200]])\n",
    "train1_y = pd.concat([y[0:l],y[l+200:2*l],y[2*l+200:length-test_size]])\n",
    "val1_y = pd.concat([y[l:l+200],y[2*l:2*l+200]])\n",
    "test1_X = X[length-test_size:]\n",
    "test1_y = y[length-test_size:]\n",
    "\n",
    "# second with the last 2 year as test\n",
    "test_size2 =365*2\n",
    "l2 =(X.shape[0]-test_size2)//3\n",
    "\n",
    "train2_X = pd.concat([X[0:l2],X[l2+180:2*l2],X[2*l2+180:length-test_size2]])\n",
    "val2_X = pd.concat([X[l2:l2+180],X[2*l2:2*l2+180]])\n",
    "train2_y = pd.concat([y[0:l2],y[l2+180:2*l2],y[2*l2+180:length-test_size2]])\n",
    "val2_y = pd.concat([y[l2:l2+180],y[2*l2:2*l2+180]])\n",
    "test2_X = X[length-test_size2:length-test_size]\n",
    "test2_y = y[length-test_size2:length-test_size]\n",
    "\n",
    "print('X shape: ',X.shape,'  y shape: ',y.shape)\n",
    "print('train1 X:',train1_X.shape,' train1 y:',train1_y.shape,' Test1 X shape:',test1_X.shape, ' Test1 y shape:',test1_y.shape)\n",
    "print('validation1 X:',val1_X.shape,' validation1 y:',val1_y.shape)\n",
    "print('train2 X:',train2_X.shape,' train2 y:',train2_y.shape,' Test2 X:',test2_X.shape,' Test2 y:',test2_y.shape)\n",
    "print('validation2 X:',val2_X.shape,' validation2 y:',val2_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 1), (500,), ('flu',), ('symptoms of kidney infection',))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = train1_X.shape[0]\n",
    "corrs = np.zeros((X.shape[1],1))\n",
    "for i in range(0,X.shape[1]):\n",
    "    if X.sum(axis=1)[i] == 0:\n",
    "        corrs[i] = 0\n",
    "    else:\n",
    "        corrs[i] = np.corrcoef(train1_X.iloc[0:train_size,i],train1_y.iloc[0:train_size,0])[0,1]\n",
    "        \n",
    "corrs.shape,X.columns.shape,X.columns[0],X.columns[499]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_filter(df_X,df_Xval,df_Xtest,corrs,threshold):\n",
    "    X = df_X.copy()\n",
    "    X_test = df_Xtest.copy()\n",
    "    X_val = df_Xval.copy()\n",
    "    col_corr = set() # Set of all the names of deleted columns\n",
    "    for i in range(0,500):\n",
    "            if corrs[i,0] < threshold: \n",
    "                #print(X.columns[i])\n",
    "                colname = df_X.columns[i]\n",
    "                del X[colname] # deleting the column from the dataset\n",
    "                del X_test[colname] \n",
    "                del X_val[colname]\n",
    "\n",
    "    return X,X_val,X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing pearson correlation filter r>=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train1_X0,test1_X0 = corr_filter(train1_X,test1_X,corrs,0.1)\n",
    "train1_X1,val1_X1,test1_X1 = corr_filter(train1_X,val1_X,test1_X,corrs,0.2)\n",
    "#train1_X2,test1_X2 = corr_filter(train1_X,test1_X,corrs,0.3)\n",
    "#train1_X3,test1_X3 = corr_filter(train1_X,test1_X,corrs,0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For correlation filter r>=0.2, we select feature number:  212\n"
     ]
    }
   ],
   "source": [
    "#print('For correlation filter r>=0.1, we select feature number: ',train1_X0.shape[1])\n",
    "print('For correlation filter r>=0.2, we select feature number: ',train1_X1.shape[1])\n",
    "#print('For correlation filter r>=0.3, we select feature number: ',train1_X2.shape[1])\n",
    "#print('For correlation filter r>=0.4, we select feature number: ',train1_X3.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defien the mearure matrics, MAE, RMSE, CORR\n",
    "# define three metrics: mean absolute error, root mean squared error and Pearson's correlation.\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# mae = mean_absolute_error(y_actual, y_pred)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "# rmse = sqrt(mean_squared_error(y_actual, y_pred))\n",
    "\n",
    "# np.correcoef returns Pearson product-moment correlation coefficients\n",
    "def pearson_r(x,y):   \n",
    "    corr_mat = np.corrcoef(x,y)\n",
    "    return corr_mat[0,1]\n",
    "# r = pearson_r(y_actual,y_pred)\n",
    "\n",
    "\n",
    "# Generalise the function for convinient tuning\n",
    "def eNet(a,l,train_X,train_y,test_X,test_y):\n",
    "    alpha = a\n",
    "    l1_ratio = l\n",
    "    enet = ElasticNet(alpha=a, l1_ratio=l, normalize=False,max_iter=10000)\n",
    "    enet.fit(train_X,train_y)\n",
    "    print('Nonzero weights: %d from %d' % (len(np.nonzero(enet.coef_)[0]), len(enet.coef_)))\n",
    "    y_pred1 = enet.predict(test_X)\n",
    "\n",
    "    mae1 = mean_absolute_error(test_y, y_pred1)\n",
    "    #print('The mean absolute error is: ',mae1)\n",
    "\n",
    "    rmse1 = sqrt(mean_squared_error(test_y, y_pred1))\n",
    "    #print('The root mean squared error is: ',rmse1)\n",
    "    \n",
    "    corr_y = test_y.copy()\n",
    "    corr_y['y_act'] = test_y\n",
    "    corr_y['y_pred']= y_pred1\n",
    "    corr = np.corrcoef(corr_y['y_act'],corr_y['y_pred'])[0,1]\n",
    "    #print('The correlation is: ',corr)\n",
    "    \n",
    "    return rmse1, mae1,corr\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scaling and modeling\n",
    "scaler = MinMaxScaler()\n",
    "train1_X0_scaled = scaler.fit_transform(train1_X0)\n",
    "test1_X0_scaled = scaler.transform(test1_x0)\n",
    "\n",
    "train1_X1_scaled = scaler.fit_transform(train1_X1)\n",
    "test1_X1_scaled = scaler.transform(test1_x1)\n",
    "\n",
    "train1_X2_scaled = scaler.fit_transform(train1_X2)\n",
    "test1_X2_scaled = scaler.transform(test1_x2)\n",
    "\n",
    "train1_X3_scaled = scaler.fit_transform(train1_X3)\n",
    "test1_X3_scaled = scaler.transform(test1_x3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "para = [10]\n",
    "para_l=[0.3]\n",
    "print('For correlation filter r>=0.1, 310 features are selected')\n",
    "for a in para:\n",
    "    for l in para_l:\n",
    "        print('alpha:',a,' L1-ratio:',l)\n",
    "        print(eNet(a,l,train1_X0,train1_y,test1_X0,test1_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For correlation filter r>=0.2, 212 features are selected\n",
      "alpha: 1  L1-ratio: 0.3\n",
      "Nonzero weights: 187 from 212\n",
      "========================================\n",
      "Best RMSE is updated! \n",
      "The mean absolute error is:  23.79700019123999\n",
      "The root mean squared error is:  48.47725961147093\n",
      "The correlation is:  0.7559666589797297\n",
      "----------------------------------------\n",
      "alpha: 2  L1-ratio: 0.3\n",
      "Nonzero weights: 163 from 212\n",
      "========================================\n",
      "Best RMSE is updated! \n",
      "The mean absolute error is:  23.554674772431007\n",
      "The root mean squared error is:  47.5205723673865\n",
      "The correlation is:  0.7717733547708276\n",
      "----------------------------------------\n",
      "alpha: 3  L1-ratio: 0.3\n",
      "Nonzero weights: 139 from 212\n",
      "========================================\n",
      "Best RMSE is updated! \n",
      "The mean absolute error is:  23.093003345532242\n",
      "The root mean squared error is:  46.201443861327974\n",
      "The correlation is:  0.7839812603418955\n",
      "----------------------------------------\n",
      "alpha: 4  L1-ratio: 0.3\n",
      "Nonzero weights: 128 from 212\n",
      "========================================\n",
      "Best RMSE is updated! \n",
      "The mean absolute error is:  22.711763659237107\n",
      "The root mean squared error is:  45.07720655118221\n",
      "The correlation is:  0.7954874130404568\n",
      "----------------------------------------\n",
      "alpha: 5  L1-ratio: 0.3\n",
      "Nonzero weights: 120 from 212\n",
      "========================================\n",
      "Best RMSE is updated! \n",
      "The mean absolute error is:  22.195499829136008\n",
      "The root mean squared error is:  43.64376243898199\n",
      "The correlation is:  0.8104738893148772\n",
      "----------------------------------------\n",
      "alpha: 6  L1-ratio: 0.3\n",
      "Nonzero weights: 106 from 212\n",
      "========================================\n",
      "Best RMSE is updated! \n",
      "The mean absolute error is:  21.77143137520172\n",
      "The root mean squared error is:  42.40556777484507\n",
      "The correlation is:  0.8244595987700274\n",
      "----------------------------------------\n",
      "alpha: 7  L1-ratio: 0.3\n",
      "Nonzero weights: 96 from 212\n",
      "========================================\n",
      "Best RMSE is updated! \n",
      "The mean absolute error is:  21.397632430747812\n",
      "The root mean squared error is:  41.31774487303899\n",
      "The correlation is:  0.8365331281245186\n",
      "----------------------------------------\n",
      "alpha: 8  L1-ratio: 0.3\n",
      "Nonzero weights: 87 from 212\n",
      "========================================\n",
      "Best RMSE is updated! \n",
      "The mean absolute error is:  20.991857363950448\n",
      "The root mean squared error is:  40.189540080422184\n",
      "The correlation is:  0.8480254312539661\n",
      "----------------------------------------\n",
      "alpha: 9  L1-ratio: 0.3\n",
      "Nonzero weights: 80 from 212\n",
      "========================================\n",
      "Best RMSE is updated! \n",
      "The mean absolute error is:  20.660568027319435\n",
      "The root mean squared error is:  39.27950455106098\n",
      "The correlation is:  0.8583123068981988\n",
      "----------------------------------------\n",
      "alpha: 10  L1-ratio: 0.3\n",
      "Nonzero weights: 69 from 212\n",
      "========================================\n",
      "Best RMSE is updated! \n",
      "The mean absolute error is:  20.51441858129531\n",
      "The root mean squared error is:  38.87952894895021\n",
      "The correlation is:  0.8645953471814107\n",
      "----------------------------------------\n",
      "alpha: 11  L1-ratio: 0.3\n",
      "Nonzero weights: 66 from 212\n",
      "========================================\n",
      "Best RMSE is updated! \n",
      "The mean absolute error is:  20.35175911164693\n",
      "The root mean squared error is:  38.45970780605965\n",
      "The correlation is:  0.8705611330987689\n",
      "----------------------------------------\n",
      "alpha: 12  L1-ratio: 0.3\n",
      "Nonzero weights: 61 from 212\n",
      "alpha: 13  L1-ratio: 0.3\n",
      "Nonzero weights: 61 from 212\n",
      "alpha: 14  L1-ratio: 0.3\n",
      "Nonzero weights: 56 from 212\n",
      "alpha: 15  L1-ratio: 0.3\n",
      "Nonzero weights: 54 from 212\n",
      "alpha: 16  L1-ratio: 0.3\n",
      "Nonzero weights: 51 from 212\n",
      "alpha: 17  L1-ratio: 0.3\n",
      "Nonzero weights: 50 from 212\n",
      "alpha: 18  L1-ratio: 0.3\n",
      "Nonzero weights: 49 from 212\n",
      "alpha: 19  L1-ratio: 0.3\n",
      "Nonzero weights: 48 from 212\n",
      "alpha: 20  L1-ratio: 0.3\n",
      "Nonzero weights: 48 from 212\n",
      "alpha: 21  L1-ratio: 0.3\n",
      "Nonzero weights: 48 from 212\n",
      "alpha: 22  L1-ratio: 0.3\n",
      "Nonzero weights: 47 from 212\n",
      "alpha: 23  L1-ratio: 0.3\n",
      "Nonzero weights: 45 from 212\n",
      "alpha: 24  L1-ratio: 0.3\n",
      "Nonzero weights: 44 from 212\n",
      "alpha: 25  L1-ratio: 0.3\n",
      "Nonzero weights: 43 from 212\n",
      "alpha: 26  L1-ratio: 0.3\n",
      "Nonzero weights: 41 from 212\n",
      "alpha: 27  L1-ratio: 0.3\n",
      "Nonzero weights: 40 from 212\n",
      "alpha: 28  L1-ratio: 0.3\n",
      "Nonzero weights: 39 from 212\n",
      "alpha: 29  L1-ratio: 0.3\n",
      "Nonzero weights: 38 from 212\n",
      "alpha: 30  L1-ratio: 0.3\n",
      "Nonzero weights: 36 from 212\n",
      "alpha: 31  L1-ratio: 0.3\n",
      "Nonzero weights: 35 from 212\n",
      "alpha: 32  L1-ratio: 0.3\n",
      "Nonzero weights: 34 from 212\n",
      "alpha: 33  L1-ratio: 0.3\n",
      "Nonzero weights: 33 from 212\n",
      "alpha: 34  L1-ratio: 0.3\n",
      "Nonzero weights: 32 from 212\n",
      "alpha: 35  L1-ratio: 0.3\n",
      "Nonzero weights: 32 from 212\n",
      "alpha: 36  L1-ratio: 0.3\n",
      "Nonzero weights: 31 from 212\n",
      "alpha: 37  L1-ratio: 0.3\n",
      "Nonzero weights: 30 from 212\n",
      "alpha: 38  L1-ratio: 0.3\n",
      "Nonzero weights: 30 from 212\n",
      "alpha: 39  L1-ratio: 0.3\n",
      "Nonzero weights: 28 from 212\n",
      "alpha: 40  L1-ratio: 0.3\n",
      "Nonzero weights: 27 from 212\n",
      "alpha: 41  L1-ratio: 0.3\n",
      "Nonzero weights: 27 from 212\n",
      "alpha: 42  L1-ratio: 0.3\n",
      "Nonzero weights: 27 from 212\n",
      "alpha: 43  L1-ratio: 0.3\n",
      "Nonzero weights: 27 from 212\n",
      "alpha: 44  L1-ratio: 0.3\n",
      "Nonzero weights: 27 from 212\n",
      "alpha: 45  L1-ratio: 0.3\n",
      "Nonzero weights: 26 from 212\n",
      "alpha: 46  L1-ratio: 0.3\n",
      "Nonzero weights: 25 from 212\n",
      "alpha: 47  L1-ratio: 0.3\n",
      "Nonzero weights: 24 from 212\n",
      "alpha: 48  L1-ratio: 0.3\n",
      "Nonzero weights: 23 from 212\n",
      "alpha: 49  L1-ratio: 0.3\n",
      "Nonzero weights: 23 from 212\n",
      "alpha: 50  L1-ratio: 0.3\n",
      "Nonzero weights: 21 from 212\n",
      "alpha: 51  L1-ratio: 0.3\n",
      "Nonzero weights: 21 from 212\n",
      "alpha: 52  L1-ratio: 0.3\n",
      "Nonzero weights: 21 from 212\n",
      "alpha: 53  L1-ratio: 0.3\n",
      "Nonzero weights: 21 from 212\n",
      "alpha: 54  L1-ratio: 0.3\n",
      "Nonzero weights: 21 from 212\n",
      "alpha: 55  L1-ratio: 0.3\n",
      "Nonzero weights: 21 from 212\n",
      "alpha: 56  L1-ratio: 0.3\n",
      "Nonzero weights: 21 from 212\n",
      "alpha: 57  L1-ratio: 0.3\n",
      "Nonzero weights: 20 from 212\n",
      "alpha: 58  L1-ratio: 0.3\n",
      "Nonzero weights: 20 from 212\n",
      "alpha: 59  L1-ratio: 0.3\n",
      "Nonzero weights: 20 from 212\n",
      "alpha: 60  L1-ratio: 0.3\n",
      "Nonzero weights: 19 from 212\n",
      "alpha: 61  L1-ratio: 0.3\n",
      "Nonzero weights: 18 from 212\n",
      "alpha: 62  L1-ratio: 0.3\n",
      "Nonzero weights: 18 from 212\n",
      "alpha: 63  L1-ratio: 0.3\n",
      "Nonzero weights: 18 from 212\n",
      "alpha: 64  L1-ratio: 0.3\n",
      "Nonzero weights: 18 from 212\n",
      "alpha: 65  L1-ratio: 0.3\n",
      "Nonzero weights: 18 from 212\n",
      "alpha: 66  L1-ratio: 0.3\n",
      "Nonzero weights: 18 from 212\n",
      "alpha: 67  L1-ratio: 0.3\n",
      "Nonzero weights: 18 from 212\n",
      "alpha: 68  L1-ratio: 0.3\n",
      "Nonzero weights: 15 from 212\n",
      "alpha: 69  L1-ratio: 0.3\n",
      "Nonzero weights: 15 from 212\n",
      "alpha: 70  L1-ratio: 0.3\n",
      "Nonzero weights: 15 from 212\n",
      "alpha: 71  L1-ratio: 0.3\n",
      "Nonzero weights: 15 from 212\n",
      "alpha: 72  L1-ratio: 0.3\n",
      "Nonzero weights: 15 from 212\n",
      "alpha: 73  L1-ratio: 0.3\n",
      "Nonzero weights: 15 from 212\n",
      "alpha: 74  L1-ratio: 0.3\n",
      "Nonzero weights: 15 from 212\n",
      "alpha: 75  L1-ratio: 0.3\n",
      "Nonzero weights: 15 from 212\n",
      "alpha: 76  L1-ratio: 0.3\n",
      "Nonzero weights: 15 from 212\n",
      "alpha: 77  L1-ratio: 0.3\n",
      "Nonzero weights: 15 from 212\n",
      "alpha: 78  L1-ratio: 0.3\n",
      "Nonzero weights: 15 from 212\n",
      "alpha: 79  L1-ratio: 0.3\n",
      "Nonzero weights: 15 from 212\n",
      "alpha: 80  L1-ratio: 0.3\n",
      "Nonzero weights: 14 from 212\n",
      "alpha: 81  L1-ratio: 0.3\n",
      "Nonzero weights: 14 from 212\n",
      "alpha: 82  L1-ratio: 0.3\n",
      "Nonzero weights: 14 from 212\n",
      "alpha: 83  L1-ratio: 0.3\n",
      "Nonzero weights: 14 from 212\n",
      "alpha: 84  L1-ratio: 0.3\n",
      "Nonzero weights: 14 from 212\n",
      "alpha: 85  L1-ratio: 0.3\n",
      "Nonzero weights: 14 from 212\n",
      "alpha: 86  L1-ratio: 0.3\n",
      "Nonzero weights: 14 from 212\n",
      "alpha: 87  L1-ratio: 0.3\n",
      "Nonzero weights: 14 from 212\n",
      "alpha: 88  L1-ratio: 0.3\n",
      "Nonzero weights: 14 from 212\n",
      "alpha: 89  L1-ratio: 0.3\n",
      "Nonzero weights: 14 from 212\n",
      "alpha: 90  L1-ratio: 0.3\n",
      "Nonzero weights: 14 from 212\n",
      "alpha: 91  L1-ratio: 0.3\n",
      "Nonzero weights: 13 from 212\n",
      "alpha: 92  L1-ratio: 0.3\n",
      "Nonzero weights: 13 from 212\n",
      "alpha: 93  L1-ratio: 0.3\n",
      "Nonzero weights: 13 from 212\n",
      "alpha: 94  L1-ratio: 0.3\n",
      "Nonzero weights: 12 from 212\n",
      "alpha: 95  L1-ratio: 0.3\n",
      "Nonzero weights: 12 from 212\n",
      "alpha: 96  L1-ratio: 0.3\n",
      "Nonzero weights: 12 from 212\n",
      "alpha: 97  L1-ratio: 0.3\n",
      "Nonzero weights: 12 from 212\n",
      "alpha: 98  L1-ratio: 0.3\n",
      "Nonzero weights: 12 from 212\n",
      "alpha: 99  L1-ratio: 0.3\n",
      "Nonzero weights: 12 from 212\n"
     ]
    }
   ],
   "source": [
    "## Fixing l1-ratio = 0.3, only tuning alpha.\n",
    "para = range(1,100)\n",
    "para_l=[0.3]\n",
    "rmse=100000\n",
    "mae=1000000\n",
    "corr=0\n",
    "print('For correlation filter r>=0.2, 212 features are selected')\n",
    "for a in para:\n",
    "    for l in para_l:\n",
    "        print('alpha:',a,' L1-ratio:',l)\n",
    "        rmse0,mae0,corr0 = eNet(a,l,train1_X1,train1_y,val1_X1,val1_y)\n",
    "        if rmse0< rmse:\n",
    "            rmse=rmse0\n",
    "            mae=mae0\n",
    "            corr = corr0\n",
    "            print('========================================')\n",
    "            print('Best RMSE is updated! ' )\n",
    "            print('The mean absolute error is: ',mae)\n",
    "            print('The root mean squared error is: ',rmse)\n",
    "            print('The correlation is: ',corr)\n",
    "            print('----------------------------------------')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3618, 212) (400, 212)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((4018, 212), (4018, 1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train1_X1.shape,val1_X1.shape)\n",
    "train3_X = train1_X1.append(val1_X1)\n",
    "train3_y = train1_y.append(val1_y)\n",
    "train3_X.shape,train3_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "para = [10]\n",
    "para_l=[0.3]\n",
    "print('For correlation filter r>=0.3, 150 features are selected')\n",
    "for a in para:\n",
    "    for l in para_l:\n",
    "        print('alpha:',a,' L1-ratio:',l)\n",
    "        print(eNet(a,l,train1_X2,train1_y,test1_X2,test1_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "para = [10]\n",
    "para_l=[0.3]\n",
    "print('For correlation filter r>=0.4, 103 features are selected')\n",
    "for a in para:\n",
    "    for l in para_l:\n",
    "        print('alpha:',a,' L1-ratio:',l)\n",
    "        print(eNet(a,l,train1_X3,train1_y,test1_X3,test1_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For correlation filter r>=0.2, 212 features are selected\n",
      "alpha: 11  L1-ratio: 0.3\n",
      "Nonzero weights: 77 from 212\n",
      "========================================\n",
      "Best RMSE is updated! \n",
      "The mean absolute error is:  2.702528763530121\n",
      "The root mean squared error is:  3.293105297614681\n",
      "The correlation is:  0.9144646439341871\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## tuned alpha based on validation set, then measure the performance for test set.\n",
    "## Fixing l1-ratio = 0.3\n",
    "para = [11]\n",
    "para_l=[0.3]\n",
    "rmse=100000\n",
    "mae=1000000\n",
    "corr=0\n",
    "print('For correlation filter r>=0.2, 212 features are selected')\n",
    "for a in para:\n",
    "    for l in para_l:\n",
    "        print('alpha:',a,' L1-ratio:',l)\n",
    "        rmse0,mae0,corr0 = eNet(a,l,train3_X,train3_y,test1_X1,test1_y)\n",
    "        if rmse0< rmse:\n",
    "            rmse=rmse0\n",
    "            mae=mae0\n",
    "            corr = corr0\n",
    "            print('========================================')\n",
    "            print('Best RMSE is updated! ' )\n",
    "            print('The mean absolute error is: ',mae)\n",
    "            print('The root mean squared error is: ',rmse)\n",
    "            print('The correlation is: ',corr)\n",
    "            print('----------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "enet = ElasticNet(alpha=11, l1_ratio=0.3, normalize=False,max_iter=10000)\n",
    "enet.fit(train3_X,train3_y)\n",
    "\n",
    "y_pred1 = enet.predict(test1_X1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "date = pd.date_range('20050824',periods=4383)\n",
    "import matplotlib.dates as mdates\n",
    "df = y.copy()\n",
    "df['y'] = y.values\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(date[4018:],df.y[4018:],label='real flu rate')\n",
    "ax.plot(date[4018:],y_pred1,label='predicted flu rate')\n",
    "# Now add the legend with some customizations.\n",
    "legend = ax.legend(loc='upper right', shadow=True,prop={'size':22})\n",
    "plt.title(\"Figure 1: Elastic Nets Regression:test on the last year, 500 candidate queries,no scaler, alpha=11, L1-ratio=0.3, pearson correlation filter r>=0.2\")\n",
    "plt.ylabel('flu rate')\n",
    "plt.xlabel('Date')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the last 2 years as the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 1), (500,), ('flu',), ('symptoms of kidney infection',))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_size2 = train2_X.shape[0]\n",
    "corrs2 = np.zeros((X.shape[1],1))\n",
    "for i in range(0,X.shape[1]):\n",
    "    if X.sum(axis=1)[i] == 0:\n",
    "        corrs2[i] = 0\n",
    "    else:\n",
    "        corrs2[i] = np.corrcoef(train2_X.iloc[0:train_size2,i],train2_y.iloc[0:train_size2,0])[0,1]\n",
    "        \n",
    "corrs2.shape,X.columns.shape,X.columns[0],X.columns[499]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train2_X0,test2_X0 = corr_filter(train2_X,test2_X,corrs2,0.1)\n",
    "train2_X1,val2_X1,test2_X1 = corr_filter(train2_X,val2_X,test2_X,corrs2,0.2)\n",
    "#train2_X2,test2_X2 = corr_filter(train2_X,test2_X,corrs2,0.3)\n",
    "#train2_X3,test2_X3 = corr_filter(train2_X,test2_X,corrs2,0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For correlation filter r>0.2, we select feature number:  222\n"
     ]
    }
   ],
   "source": [
    "#print('For correlation filter r>0.1, we select feature number: ',train2_X0.shape[1])\n",
    "print('For correlation filter r>0.2, we select feature number: ',train2_X1.shape[1])\n",
    "#print('For correlation filter r>0.3, we select feature number: ',train2_X2.shape[1])\n",
    "#print('For correlation filter r>0.4, we select feature number: ',train2_X3.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scaling and modeling\n",
    "scaler = MinMaxScaler()\n",
    "train2_X0_scaled = scaler.fit_transform(train2_X0)\n",
    "test2_X0_scaled = scaler.transform(test2_X0)\n",
    "\n",
    "train2_X1_scaled = scaler.fit_transform(train2_X1)\n",
    "test2_X1_scaled = scaler.transform(test2_X1)\n",
    "\n",
    "train2_X2_scaled = scaler.fit_transform(train2_X2)\n",
    "test2_X2_scaled = scaler.transform(test2_X2)\n",
    "\n",
    "train2_X3_scaled = scaler.fit_transform(train2_X3)\n",
    "test2_X3_scaled = scaler.transform(test2_X3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "para = range(1,100)\n",
    "para_l=[0.3]\n",
    "rmse=100000\n",
    "mae=1000000\n",
    "corr=0\n",
    "print('For correlation filter r>=0.1, 303 features are selected')\n",
    "for a in para:\n",
    "    for l in para_l:\n",
    "        print('alpha:',a,' L1-ratio:',l)\n",
    "        rmse0,mae0,corr0 = eNet(a,l,train2_X1,train2_y,val2_X1,val2_y)\n",
    "        if rmse0< rmse:\n",
    "            rmse=rmse0\n",
    "            mae=mae0\n",
    "            corr = corr0\n",
    "            print('========================================')\n",
    "            print('Best RMSE is updated! ' )\n",
    "            print('The mean absolute error is: ',mae)\n",
    "            print('The root mean squared error is: ',rmse)\n",
    "            print('The correlation is: ',corr)\n",
    "            print('----------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For correlation filter r>=0.1, 303 features are selected\n",
      "alpha: 30.5  L1-ratio: 0.3\n",
      "Nonzero weights: 38 from 222\n",
      "========================================\n",
      "Best RMSE is updated! \n",
      "The mean absolute error is:  3.7058261094117313\n",
      "The root mean squared error is:  6.264982831469201\n",
      "The correlation is:  0.5743841816805204\n",
      "----------------------------------------\n",
      "alpha: 30.6  L1-ratio: 0.3\n",
      "Nonzero weights: 38 from 222\n",
      "========================================\n",
      "Best RMSE is updated! \n",
      "The mean absolute error is:  3.7064331411745752\n",
      "The root mean squared error is:  6.2649669842610125\n",
      "The correlation is:  0.5743388389088894\n",
      "----------------------------------------\n",
      "alpha: 30.7  L1-ratio: 0.3\n",
      "Nonzero weights: 38 from 222\n",
      "========================================\n",
      "Best RMSE is updated! \n",
      "The mean absolute error is:  3.7070368995085623\n",
      "The root mean squared error is:  6.264948876728592\n",
      "The correlation is:  0.5742938226039611\n",
      "----------------------------------------\n",
      "alpha: 30.8  L1-ratio: 0.3\n",
      "Nonzero weights: 38 from 222\n",
      "========================================\n",
      "Best RMSE is updated! \n",
      "The mean absolute error is:  3.707642517392559\n",
      "The root mean squared error is:  6.26494371540803\n",
      "The correlation is:  0.5742471942712747\n",
      "----------------------------------------\n",
      "alpha: 30.9  L1-ratio: 0.3\n",
      "Nonzero weights: 38 from 222\n",
      "alpha: 31  L1-ratio: 0.3\n",
      "Nonzero weights: 38 from 222\n",
      "alpha: 31.2  L1-ratio: 0.3\n",
      "Nonzero weights: 38 from 222\n",
      "alpha: 31.4  L1-ratio: 0.3\n",
      "Nonzero weights: 38 from 222\n",
      "alpha: 31.5  L1-ratio: 0.3\n",
      "Nonzero weights: 38 from 222\n"
     ]
    }
   ],
   "source": [
    "para = [30.5,30.6,30.7,30.8,30.9,31,31.2,31.4,31.5]\n",
    "para_l=[0.3]\n",
    "rmse=100000\n",
    "mae=1000000\n",
    "corr=0\n",
    "print('For correlation filter r>=0.1, 303 features are selected')\n",
    "for a in para:\n",
    "    for l in para_l:\n",
    "        print('alpha:',a,' L1-ratio:',l)\n",
    "        rmse0,mae0,corr0 = eNet(a,l,train2_X1,train2_y,val2_X1,val2_y)\n",
    "        if rmse0< rmse:\n",
    "            rmse=rmse0\n",
    "            mae=mae0\n",
    "            corr = corr0\n",
    "            print('========================================')\n",
    "            print('Best RMSE is updated! ' )\n",
    "            print('The mean absolute error is: ',mae)\n",
    "            print('The root mean squared error is: ',rmse)\n",
    "            print('The correlation is: ',corr)\n",
    "            print('----------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "para = [10]\n",
    "para_l=[0.3]\n",
    "print('For correlation filter r>=0.3, 154 features are selected')\n",
    "for a in para:\n",
    "    for l in para_l:\n",
    "        print('alpha:',a,' L1-ratio:',l)\n",
    "        print(eNet(a,l,train2_X2,train2_y,test2_X2,test2_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "para = [10]\n",
    "para_l=[0.3]\n",
    "print('For correlation filter r>=0.4, 105 features are selected')\n",
    "for a in para:\n",
    "    for l in para_l:\n",
    "        print('alpha:',a,' L1-ratio:',l)\n",
    "        print(eNet(a,l,train2_X3,train2_y,test2_X3,test2_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3293, 222) (360, 222)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3653, 222), (3653, 1))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train2_X1.shape,val2_X1.shape)\n",
    "train4_X = train2_X1.append(val2_X1)\n",
    "train4_y = train2_y.append(val2_y)\n",
    "train4_X.shape,train4_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For correlation filter r>=0.2, 212 features are selected\n",
      "alpha: 30.8  L1-ratio: 0.3\n",
      "Nonzero weights: 42 from 222\n",
      "========================================\n",
      "Best RMSE is updated! \n",
      "The mean absolute error is:  2.6979770123790288\n",
      "The root mean squared error is:  3.388061270019553\n",
      "The correlation is:  0.9116412064723197\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## tuned alpha based on validation set, then measure the performance for test set.\n",
    "## Fixing l1-ratio = 0.3\n",
    "para = [30.8]\n",
    "para_l=[0.3]\n",
    "rmse=100000\n",
    "mae=1000000\n",
    "corr=0\n",
    "print('For correlation filter r>=0.2, 212 features are selected')\n",
    "for a in para:\n",
    "    for l in para_l:\n",
    "        print('alpha:',a,' L1-ratio:',l)\n",
    "        rmse0,mae0,corr0 = eNet(a,l,train4_X,train4_y,test2_X1,test2_y)\n",
    "        if rmse0< rmse:\n",
    "            rmse=rmse0\n",
    "            mae=mae0\n",
    "            corr = corr0\n",
    "            print('========================================')\n",
    "            print('Best RMSE is updated! ' )\n",
    "            print('The mean absolute error is: ',mae)\n",
    "            print('The root mean squared error is: ',rmse)\n",
    "            print('The correlation is: ',corr)\n",
    "            print('----------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enet = ElasticNet(alpha=31, l1_ratio=0.3, normalize=False,max_iter=10000)\n",
    "enet.fit(train4_X,train4_y)\n",
    "\n",
    "y_pred2 = enet.predict(test2_X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "date = pd.date_range('20050824',periods=4383)\n",
    "import matplotlib.dates as mdates\n",
    "df = y.copy()\n",
    "df['y'] = y.values\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(date[3653:4018],df.y[3653:4018],label='real flu rate')\n",
    "ax.plot(date[3653:4018],y_pred2,label='predicted flu rate')\n",
    "# Now add the legend with some customizations.\n",
    "legend = ax.legend(loc='upper right', shadow=True,prop={'size':22})\n",
    "plt.title(\"Figure 2: Elastic Nets Regression:test on second last year, 500 candidate queries,no scaler, alpha=31, L1-ratio=0.3, pearson correlation filter r>=0.2\")\n",
    "plt.ylabel('flu rate')\n",
    "plt.xlabel('Date')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
