{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import csv\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import math\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from random import randint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.nonparametric.kde import KDEUnivariate\n",
    "from statsmodels.nonparametric import smoothers_lowess\n",
    "from pandas import Series, DataFrame\n",
    "from patsy import dmatrices\n",
    "from sklearn import datasets, svm\n",
    "\n",
    "# initialize the plotting sizes\n",
    "# set size\n",
    "plt.rc('figure', figsize=(15, 8))\n",
    "# subplots size\n",
    "fizsize_with_subplots = (15, 8)\n",
    "# histogram size\n",
    "bin_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "dates = pd.read_csv('data/dates.csv',header=None)\n",
    "queries = pd.read_csv('data/queries.csv',header=None)\n",
    "X = pd.read_csv('data/X.csv',header=None)\n",
    "y = pd.read_csv('data/y.csv',header=None)\n",
    "\n",
    "X.columns = queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (4383, 500)   y shape:  (4383, 1)\n",
      "train1 X: (3653, 500)  train1 y: (3653, 1)  Test1 X shape: (365, 500)  Test1 y shape: (365, 1)\n",
      "train2 X: (3288, 500)  train2 y: (3288, 1)  Test2 X: (730, 500)  Test2 y: (730, 1)\n"
     ]
    }
   ],
   "source": [
    "# data preprocessing and train-test split\n",
    "# this data is well formed with no missing value and other symbols or labels that are non numerical.\n",
    "# splitting the data into train and test\n",
    "\n",
    "# Here we want the first 500 queries, ARIAMA only consider y, setting X has no effect\n",
    "X = X.iloc[:, 0: 500]\n",
    "\n",
    "# first with the last year as test\n",
    "# use the last 365 of training set as validation set\n",
    "test_size =365\n",
    "val_size=365\n",
    "length = X.shape[0]\n",
    "train1_X = X[0:length-test_size*2]\n",
    "val1_X = X[length-test_size*2:length-test_size]\n",
    "train1_y = y[0:length-test_size*2]\n",
    "val1_y = y[length-test_size*2:length-test_size]\n",
    "test1_X = X[length-test_size:]\n",
    "test1_y = y[length-test_size:]\n",
    "\n",
    "#without validation set\n",
    "train1_X2 = X[0:length-test_size]\n",
    "train1_y2 = y[0:length-test_size]\n",
    "\n",
    "# second with the last 2 year as test\n",
    "test_size2 =365*2\n",
    "train2_X = X[0:length-test_size2-val_size]\n",
    "val2_X = X[length-test_size2-val_size:length-test_size2]\n",
    "train2_y = y[0:length-test_size2-val_size]\n",
    "val2_y = y[length-test_size2-val_size:length-test_size2]\n",
    "test2_X = X[length-test_size2:]\n",
    "test2_y = y[length-test_size2:]\n",
    "\n",
    "#without validation set\n",
    "train2_X2 = X[0:length-test_size2]\n",
    "train2_y2 = y[0:length-test_size2]\n",
    "\n",
    "\n",
    "print('X shape: ',X.shape,'  y shape: ',y.shape)\n",
    "print('train1 X:',train1_X.shape,' train1 y:',train1_y.shape,' Test1 X shape:',test1_X.shape, ' Test1 y shape:',test1_y.shape)\n",
    "print('train2 X:',train2_X.shape,' train2 y:',train2_y.shape,' Test2 X:',test2_X.shape,' Test2 y:',test2_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonzero weights: 170 from 500\n"
     ]
    }
   ],
   "source": [
    "# using first 4 years predicting the 5th, then first 5 predict 6th, until first 10 predicting 11th, \n",
    "# then all together as exogenous variable of arimax predicting test set\n",
    "alpha = 11\n",
    "l1_ratio = 0.3\n",
    "X_train = train1_X2[0:4*365]\n",
    "y_train= train1_y2[0:4*365]\n",
    "X_test = train1_X2[4*365:5*365]\n",
    "enet = ElasticNet(alpha=11, l1_ratio=0.3, normalize=False,max_iter=10000)\n",
    "enet.fit(X_train,y_train)\n",
    "print('Nonzero weights: %d from %d' % (len(np.nonzero(enet.coef_)[0]), len(enet.coef_)))\n",
    "y_pred5 = enet.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonzero weights: 138 from 500\n"
     ]
    }
   ],
   "source": [
    "X_train = train1_X2[365:5*365]\n",
    "y_train= train1_y2[365:5*365]\n",
    "X_test = train1_X2[5*365:6*365]\n",
    "enet = ElasticNet(alpha=11, l1_ratio=0.3, normalize=False,max_iter=10000)\n",
    "enet.fit(X_train,y_train)\n",
    "print('Nonzero weights: %d from %d' % (len(np.nonzero(enet.coef_)[0]), len(enet.coef_)))\n",
    "y_pred6 = enet.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonzero weights: 155 from 500\n"
     ]
    }
   ],
   "source": [
    "X_train = train1_X2[2*365:6*365]\n",
    "y_train= train1_y2[2*365:6*365]\n",
    "X_test = train1_X2[6*365:7*365]\n",
    "enet = ElasticNet(alpha=11, l1_ratio=0.3, normalize=False,max_iter=10000)\n",
    "enet.fit(X_train,y_train)\n",
    "print('Nonzero weights: %d from %d' % (len(np.nonzero(enet.coef_)[0]), len(enet.coef_)))\n",
    "y_pred7 = enet.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonzero weights: 146 from 500\n"
     ]
    }
   ],
   "source": [
    "X_train = train1_X2[3*365:7*365]\n",
    "y_train= train1_y2[3*365:7*365]\n",
    "X_test = train1_X2[7*365:8*365]\n",
    "enet = ElasticNet(alpha=11, l1_ratio=0.3, normalize=False,max_iter=10000)\n",
    "enet.fit(X_train,y_train)\n",
    "print('Nonzero weights: %d from %d' % (len(np.nonzero(enet.coef_)[0]), len(enet.coef_)))\n",
    "y_pred8 = enet.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonzero weights: 96 from 500\n"
     ]
    }
   ],
   "source": [
    "X_train = train1_X2[4*365:8*365]\n",
    "y_train= train1_y2[4*365:8*365]\n",
    "X_test = train1_X2[8*365:9*365]\n",
    "enet = ElasticNet(alpha=11, l1_ratio=0.3, normalize=False,max_iter=10000)\n",
    "enet.fit(X_train,y_train)\n",
    "print('Nonzero weights: %d from %d' % (len(np.nonzero(enet.coef_)[0]), len(enet.coef_)))\n",
    "y_pred9 = enet.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonzero weights: 62 from 500\n"
     ]
    }
   ],
   "source": [
    "X_train = train1_X2[5*365:9*365]\n",
    "y_train= train1_y2[5*365:9*365]\n",
    "X_test = train1_X2[9*365:10*365]\n",
    "enet = ElasticNet(alpha=11, l1_ratio=0.3, normalize=False,max_iter=10000)\n",
    "enet.fit(X_train,y_train)\n",
    "print('Nonzero weights: %d from %d' % (len(np.nonzero(enet.coef_)[0]), len(enet.coef_)))\n",
    "y_pred10 = enet.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonzero weights: 29 from 500\n"
     ]
    }
   ],
   "source": [
    "X_train = train1_X2[6*365:10*365]\n",
    "y_train= train1_y2[6*365:10*365]\n",
    "X_test = train1_X2[10*365:]\n",
    "enet = ElasticNet(alpha=11, l1_ratio=0.3, normalize=False,max_iter=10000)\n",
    "enet.fit(X_train,y_train)\n",
    "print('Nonzero weights: %d from %d' % (len(np.nonzero(enet.coef_)[0]), len(enet.coef_)))\n",
    "y_pred11 = enet.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonzero weights: 29 from 500\n"
     ]
    }
   ],
   "source": [
    "X_train = train1_X2[7*365:4018]\n",
    "y_train= train1_y2[7*365:4018]\n",
    "X_test = test1_X\n",
    "enet = ElasticNet(alpha=11, l1_ratio=0.3, normalize=False,max_iter=10000)\n",
    "enet.fit(X_train,y_train)\n",
    "print('Nonzero weights: %d from %d' % (len(np.nonzero(enet.coef_)[0]), len(enet.coef_)))\n",
    "y_pred12 = enet.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.concatenate((y_pred5, y_pred6,y_pred7,y_pred8,y_pred9,y_pred10,y_pred11,y_pred12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2923,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_x = pd.DataFrame(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.730904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.894386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.499658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.090033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.817456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0  16.730904\n",
       "1  10.894386\n",
       "2  19.499658\n",
       "3  15.090033\n",
       "4  10.817456"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EN_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_x.to_csv('EN_exog_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
